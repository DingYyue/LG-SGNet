[ Sun Jul 23 22:35:29 2023 ] Load weights from /21085401076/pretrained_model/pretrained_model/CTRGCN_NTU120_CSub_bone_motion_81.2/runs-62-61008.pt.
[ Sun Jul 23 22:35:33 2023 ] using warm up, epoch: 5
[ Sun Jul 23 22:36:10 2023 ] Parameters:
{'work_dir': 'train/ntu120/xsub/multihead3tanh_ctrgcn_bone_motion', 'model_saved_name': 'train/ntu120/xsub/multihead3tanh_ctrgcn_bone_motion/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': '/21085401076/data/home/sdc1/dy/CTR-GCN-main/CTR-GCN-main/data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': True}, 'test_feeder_args': {'data_path': '/21085401076/data/home/sdc1/dy/CTR-GCN-main/CTR-GCN-main/data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': True, 'debug': False}, 'model': 'model.ctrgcn.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': '/21085401076/pretrained_model/pretrained_model/CTRGCN_NTU120_CSub_bone_motion_81.2/runs-62-61008.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55, 75], 'device': [0, 1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 85, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Sun Jul 23 22:36:10 2023 ] # Parameters: 1745788
[ Sun Jul 23 22:36:10 2023 ] Training epoch: 1
[ Sun Jul 23 23:07:14 2023 ] 	Mean training loss: 0.7991.  Mean training acc: 76.41%.
[ Sun Jul 23 23:07:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sun Jul 23 23:07:14 2023 ] Eval epoch: 1
[ Sun Jul 23 23:19:53 2023 ] 	Mean test loss of 796 batches: 2.474744496183779.
[ Sun Jul 23 23:19:54 2023 ] 	Top1: 69.70%
[ Sun Jul 23 23:19:54 2023 ] 	Top5: 91.75%
[ Sun Jul 23 23:19:54 2023 ] Training epoch: 2
[ Sun Jul 23 23:50:38 2023 ] 	Mean training loss: 0.8117.  Mean training acc: 75.78%.
[ Sun Jul 23 23:50:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Sun Jul 23 23:50:38 2023 ] Eval epoch: 2
[ Mon Jul 24 00:03:14 2023 ] 	Mean test loss of 796 batches: 0.9976814432659341.
[ Mon Jul 24 00:03:14 2023 ] 	Top1: 71.72%
[ Mon Jul 24 00:03:15 2023 ] 	Top5: 92.96%
[ Mon Jul 24 00:03:15 2023 ] Training epoch: 3
[ Mon Jul 24 00:34:06 2023 ] 	Mean training loss: 0.8537.  Mean training acc: 74.51%.
[ Mon Jul 24 00:34:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 00:34:06 2023 ] Eval epoch: 3
[ Mon Jul 24 00:46:50 2023 ] 	Mean test loss of 796 batches: 1.0976685097618917.
[ Mon Jul 24 00:46:50 2023 ] 	Top1: 69.64%
[ Mon Jul 24 00:46:51 2023 ] 	Top5: 92.00%
[ Mon Jul 24 00:46:51 2023 ] Training epoch: 4
[ Mon Jul 24 01:17:40 2023 ] 	Mean training loss: 0.8872.  Mean training acc: 73.58%.
[ Mon Jul 24 01:17:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 01:17:40 2023 ] Eval epoch: 4
[ Mon Jul 24 01:30:29 2023 ] 	Mean test loss of 796 batches: 1.3814181305430642.
[ Mon Jul 24 01:30:29 2023 ] 	Top1: 68.20%
[ Mon Jul 24 01:30:30 2023 ] 	Top5: 91.28%
[ Mon Jul 24 01:30:30 2023 ] Training epoch: 5
[ Mon Jul 24 02:01:23 2023 ] 	Mean training loss: 0.9431.  Mean training acc: 72.40%.
[ Mon Jul 24 02:01:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 02:01:23 2023 ] Eval epoch: 5
[ Mon Jul 24 02:14:01 2023 ] 	Mean test loss of 796 batches: 47.98798118048727.
[ Mon Jul 24 02:14:01 2023 ] 	Top1: 64.67%
[ Mon Jul 24 02:14:02 2023 ] 	Top5: 88.20%
[ Mon Jul 24 02:14:02 2023 ] Training epoch: 6
[ Mon Jul 24 02:44:51 2023 ] 	Mean training loss: 0.9171.  Mean training acc: 72.66%.
[ Mon Jul 24 02:44:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 02:44:51 2023 ] Eval epoch: 6
[ Mon Jul 24 02:57:32 2023 ] 	Mean test loss of 796 batches: 6.845113893661966.
[ Mon Jul 24 02:57:33 2023 ] 	Top1: 61.79%
[ Mon Jul 24 02:57:33 2023 ] 	Top5: 88.08%
[ Mon Jul 24 02:57:33 2023 ] Training epoch: 7
[ Mon Jul 24 03:28:25 2023 ] 	Mean training loss: 0.9024.  Mean training acc: 73.41%.
[ Mon Jul 24 03:28:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 03:28:25 2023 ] Eval epoch: 7
[ Mon Jul 24 03:40:57 2023 ] 	Mean test loss of 796 batches: 4.73931052400988.
[ Mon Jul 24 03:40:58 2023 ] 	Top1: 60.00%
[ Mon Jul 24 03:40:58 2023 ] 	Top5: 87.20%
[ Mon Jul 24 03:40:59 2023 ] Training epoch: 8
[ Mon Jul 24 04:11:47 2023 ] 	Mean training loss: 0.9107.  Mean training acc: 73.14%.
[ Mon Jul 24 04:11:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 04:11:47 2023 ] Eval epoch: 8
[ Mon Jul 24 04:24:20 2023 ] 	Mean test loss of 796 batches: 1.7194481916613316.
[ Mon Jul 24 04:24:21 2023 ] 	Top1: 53.73%
[ Mon Jul 24 04:24:21 2023 ] 	Top5: 82.69%
[ Mon Jul 24 04:24:22 2023 ] Training epoch: 9
[ Mon Jul 24 04:55:19 2023 ] 	Mean training loss: 0.8991.  Mean training acc: 73.46%.
[ Mon Jul 24 04:55:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 04:55:19 2023 ] Eval epoch: 9
[ Mon Jul 24 05:07:51 2023 ] 	Mean test loss of 796 batches: 1.2687823559396232.
[ Mon Jul 24 05:07:52 2023 ] 	Top1: 65.17%
[ Mon Jul 24 05:07:52 2023 ] 	Top5: 90.52%
[ Mon Jul 24 05:07:52 2023 ] Training epoch: 10
[ Mon Jul 24 05:38:51 2023 ] 	Mean training loss: 0.9041.  Mean training acc: 73.33%.
[ Mon Jul 24 05:38:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 05:38:51 2023 ] Eval epoch: 10
[ Mon Jul 24 05:51:28 2023 ] 	Mean test loss of 796 batches: 1.248503764707539.
[ Mon Jul 24 05:51:28 2023 ] 	Top1: 66.56%
[ Mon Jul 24 05:51:29 2023 ] 	Top5: 90.11%
[ Mon Jul 24 05:51:29 2023 ] Training epoch: 11
[ Mon Jul 24 06:22:18 2023 ] 	Mean training loss: 0.8980.  Mean training acc: 73.40%.
[ Mon Jul 24 06:22:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 06:22:18 2023 ] Eval epoch: 11
[ Mon Jul 24 06:35:01 2023 ] 	Mean test loss of 796 batches: 1.3229031004573233.
[ Mon Jul 24 06:35:01 2023 ] 	Top1: 62.75%
[ Mon Jul 24 06:35:02 2023 ] 	Top5: 88.65%
[ Mon Jul 24 06:35:02 2023 ] Training epoch: 12
[ Mon Jul 24 07:05:48 2023 ] 	Mean training loss: 0.9009.  Mean training acc: 73.40%.
[ Mon Jul 24 07:05:48 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 07:05:48 2023 ] Eval epoch: 12
[ Mon Jul 24 07:18:32 2023 ] 	Mean test loss of 796 batches: 1.2418612873733943.
[ Mon Jul 24 07:18:33 2023 ] 	Top1: 65.61%
[ Mon Jul 24 07:18:33 2023 ] 	Top5: 91.38%
[ Mon Jul 24 07:18:33 2023 ] Training epoch: 13
[ Mon Jul 24 07:49:46 2023 ] 	Mean training loss: 0.8949.  Mean training acc: 73.56%.
[ Mon Jul 24 07:49:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 07:49:46 2023 ] Eval epoch: 13
[ Mon Jul 24 08:02:36 2023 ] 	Mean test loss of 796 batches: 1.3448106879789625.
[ Mon Jul 24 08:02:36 2023 ] 	Top1: 63.95%
[ Mon Jul 24 08:02:37 2023 ] 	Top5: 89.09%
[ Mon Jul 24 08:02:37 2023 ] Training epoch: 14
[ Mon Jul 24 08:33:51 2023 ] 	Mean training loss: 0.8955.  Mean training acc: 73.47%.
[ Mon Jul 24 08:33:51 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 08:33:51 2023 ] Eval epoch: 14
[ Mon Jul 24 08:46:22 2023 ] 	Mean test loss of 796 batches: 1.0735108513927938.
[ Mon Jul 24 08:46:22 2023 ] 	Top1: 68.32%
[ Mon Jul 24 08:46:23 2023 ] 	Top5: 92.09%
[ Mon Jul 24 08:46:23 2023 ] Training epoch: 15
[ Mon Jul 24 09:17:38 2023 ] 	Mean training loss: 0.8906.  Mean training acc: 73.61%.
[ Mon Jul 24 09:17:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 09:17:38 2023 ] Eval epoch: 15
[ Mon Jul 24 09:30:15 2023 ] 	Mean test loss of 796 batches: 1.2220413880656713.
[ Mon Jul 24 09:30:15 2023 ] 	Top1: 64.79%
[ Mon Jul 24 09:30:16 2023 ] 	Top5: 90.98%
[ Mon Jul 24 09:30:16 2023 ] Training epoch: 16
[ Mon Jul 24 10:01:23 2023 ] 	Mean training loss: 0.8976.  Mean training acc: 73.51%.
[ Mon Jul 24 10:01:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 10:01:23 2023 ] Eval epoch: 16
[ Mon Jul 24 10:14:07 2023 ] 	Mean test loss of 796 batches: 1.2145920416068792.
[ Mon Jul 24 10:14:07 2023 ] 	Top1: 65.65%
[ Mon Jul 24 10:14:08 2023 ] 	Top5: 89.32%
[ Mon Jul 24 10:14:08 2023 ] Training epoch: 17
[ Mon Jul 24 10:44:45 2023 ] 	Mean training loss: 0.8864.  Mean training acc: 73.64%.
[ Mon Jul 24 10:44:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 10:44:45 2023 ] Eval epoch: 17
[ Mon Jul 24 10:57:07 2023 ] 	Mean test loss of 796 batches: 1.2209711078947514.
[ Mon Jul 24 10:57:08 2023 ] 	Top1: 63.99%
[ Mon Jul 24 10:57:08 2023 ] 	Top5: 90.61%
[ Mon Jul 24 10:57:08 2023 ] Training epoch: 18
[ Mon Jul 24 11:27:09 2023 ] 	Mean training loss: 0.8851.  Mean training acc: 73.85%.
[ Mon Jul 24 11:27:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 11:27:09 2023 ] Eval epoch: 18
[ Mon Jul 24 11:39:33 2023 ] 	Mean test loss of 796 batches: 1.109953608494907.
[ Mon Jul 24 11:39:33 2023 ] 	Top1: 67.93%
[ Mon Jul 24 11:39:34 2023 ] 	Top5: 92.13%
[ Mon Jul 24 11:39:34 2023 ] Training epoch: 19
[ Mon Jul 24 12:09:34 2023 ] 	Mean training loss: 0.8724.  Mean training acc: 74.00%.
[ Mon Jul 24 12:09:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 12:09:34 2023 ] Eval epoch: 19
[ Mon Jul 24 12:21:57 2023 ] 	Mean test loss of 796 batches: 1.1175646552787952.
[ Mon Jul 24 12:21:57 2023 ] 	Top1: 68.72%
[ Mon Jul 24 12:21:58 2023 ] 	Top5: 91.35%
[ Mon Jul 24 12:21:58 2023 ] Training epoch: 20
[ Mon Jul 24 12:52:12 2023 ] 	Mean training loss: 0.8820.  Mean training acc: 73.87%.
[ Mon Jul 24 12:52:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 12:52:12 2023 ] Eval epoch: 20
[ Mon Jul 24 13:04:38 2023 ] 	Mean test loss of 796 batches: 1.190174132735286.
[ Mon Jul 24 13:04:38 2023 ] 	Top1: 66.30%
[ Mon Jul 24 13:04:39 2023 ] 	Top5: 90.77%
[ Mon Jul 24 13:04:39 2023 ] Training epoch: 21
[ Mon Jul 24 13:34:35 2023 ] 	Mean training loss: 0.8760.  Mean training acc: 74.07%.
[ Mon Jul 24 13:34:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 13:34:35 2023 ] Eval epoch: 21
[ Mon Jul 24 13:47:01 2023 ] 	Mean test loss of 796 batches: 1.0918002342758466.
[ Mon Jul 24 13:47:01 2023 ] 	Top1: 68.31%
[ Mon Jul 24 13:47:02 2023 ] 	Top5: 91.57%
[ Mon Jul 24 13:47:02 2023 ] Training epoch: 22
[ Mon Jul 24 14:17:01 2023 ] 	Mean training loss: 0.8729.  Mean training acc: 74.02%.
[ Mon Jul 24 14:17:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 14:17:01 2023 ] Eval epoch: 22
[ Mon Jul 24 14:29:27 2023 ] 	Mean test loss of 796 batches: 1.2917384762859823.
[ Mon Jul 24 14:29:27 2023 ] 	Top1: 63.50%
[ Mon Jul 24 14:29:27 2023 ] 	Top5: 89.44%
[ Mon Jul 24 14:29:28 2023 ] Training epoch: 23
[ Mon Jul 24 14:59:22 2023 ] 	Mean training loss: 0.8754.  Mean training acc: 73.98%.
[ Mon Jul 24 14:59:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 14:59:22 2023 ] Eval epoch: 23
[ Mon Jul 24 15:11:48 2023 ] 	Mean test loss of 796 batches: 1.3092417542134698.
[ Mon Jul 24 15:11:49 2023 ] 	Top1: 63.14%
[ Mon Jul 24 15:11:49 2023 ] 	Top5: 89.45%
[ Mon Jul 24 15:11:49 2023 ] Training epoch: 24
[ Mon Jul 24 15:41:44 2023 ] 	Mean training loss: 0.8686.  Mean training acc: 74.17%.
[ Mon Jul 24 15:41:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 15:41:44 2023 ] Eval epoch: 24
[ Mon Jul 24 15:54:13 2023 ] 	Mean test loss of 796 batches: 1.2535077376132036.
[ Mon Jul 24 15:54:14 2023 ] 	Top1: 64.34%
[ Mon Jul 24 15:54:14 2023 ] 	Top5: 89.52%
[ Mon Jul 24 15:54:14 2023 ] Training epoch: 25
[ Mon Jul 24 16:24:09 2023 ] 	Mean training loss: 0.8689.  Mean training acc: 74.43%.
[ Mon Jul 24 16:24:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 16:24:09 2023 ] Eval epoch: 25
[ Mon Jul 24 16:36:33 2023 ] 	Mean test loss of 796 batches: 1.1782076483096309.
[ Mon Jul 24 16:36:33 2023 ] 	Top1: 66.18%
[ Mon Jul 24 16:36:34 2023 ] 	Top5: 90.30%
[ Mon Jul 24 16:36:34 2023 ] Training epoch: 26
[ Mon Jul 24 17:06:32 2023 ] 	Mean training loss: 0.8701.  Mean training acc: 74.05%.
[ Mon Jul 24 17:06:32 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 17:06:32 2023 ] Eval epoch: 26
[ Mon Jul 24 17:19:00 2023 ] 	Mean test loss of 796 batches: 1.1844661741999525.
[ Mon Jul 24 17:19:00 2023 ] 	Top1: 65.25%
[ Mon Jul 24 17:19:00 2023 ] 	Top5: 90.86%
[ Mon Jul 24 17:19:01 2023 ] Training epoch: 27
[ Mon Jul 24 17:48:59 2023 ] 	Mean training loss: 0.8692.  Mean training acc: 74.28%.
[ Mon Jul 24 17:48:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 17:48:59 2023 ] Eval epoch: 27
[ Mon Jul 24 18:01:27 2023 ] 	Mean test loss of 796 batches: 1.0762049981472481.
[ Mon Jul 24 18:01:27 2023 ] 	Top1: 68.87%
[ Mon Jul 24 18:01:28 2023 ] 	Top5: 91.90%
[ Mon Jul 24 18:01:28 2023 ] Training epoch: 28
[ Mon Jul 24 18:31:25 2023 ] 	Mean training loss: 0.8705.  Mean training acc: 74.23%.
[ Mon Jul 24 18:31:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 18:31:25 2023 ] Eval epoch: 28
[ Mon Jul 24 18:43:51 2023 ] 	Mean test loss of 796 batches: 1.1432888249131903.
[ Mon Jul 24 18:43:51 2023 ] 	Top1: 67.05%
[ Mon Jul 24 18:43:52 2023 ] 	Top5: 91.36%
[ Mon Jul 24 18:43:52 2023 ] Training epoch: 29
[ Mon Jul 24 19:13:49 2023 ] 	Mean training loss: 0.8633.  Mean training acc: 74.48%.
[ Mon Jul 24 19:13:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 19:13:49 2023 ] Eval epoch: 29
[ Mon Jul 24 19:26:15 2023 ] 	Mean test loss of 796 batches: 1.0514208851148135.
[ Mon Jul 24 19:26:16 2023 ] 	Top1: 68.59%
[ Mon Jul 24 19:26:16 2023 ] 	Top5: 92.37%
[ Mon Jul 24 19:26:16 2023 ] Training epoch: 30
[ Mon Jul 24 19:56:10 2023 ] 	Mean training loss: 0.8584.  Mean training acc: 74.58%.
[ Mon Jul 24 19:56:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 19:56:10 2023 ] Eval epoch: 30
[ Mon Jul 24 20:08:39 2023 ] 	Mean test loss of 796 batches: 1.0700411029796504.
[ Mon Jul 24 20:08:39 2023 ] 	Top1: 68.91%
[ Mon Jul 24 20:08:40 2023 ] 	Top5: 91.99%
[ Mon Jul 24 20:08:40 2023 ] Training epoch: 31
[ Mon Jul 24 20:38:37 2023 ] 	Mean training loss: 0.8625.  Mean training acc: 74.40%.
[ Mon Jul 24 20:38:37 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 20:38:38 2023 ] Eval epoch: 31
[ Mon Jul 24 20:51:06 2023 ] 	Mean test loss of 796 batches: 1.1476103798977693.
[ Mon Jul 24 20:51:06 2023 ] 	Top1: 67.29%
[ Mon Jul 24 20:51:07 2023 ] 	Top5: 91.20%
[ Mon Jul 24 20:51:07 2023 ] Training epoch: 32
[ Mon Jul 24 21:21:04 2023 ] 	Mean training loss: 0.8576.  Mean training acc: 74.50%.
[ Mon Jul 24 21:21:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 21:21:05 2023 ] Eval epoch: 32
[ Mon Jul 24 21:33:33 2023 ] 	Mean test loss of 796 batches: 1.424074974641129.
[ Mon Jul 24 21:33:33 2023 ] 	Top1: 60.61%
[ Mon Jul 24 21:33:34 2023 ] 	Top5: 87.28%
[ Mon Jul 24 21:33:34 2023 ] Training epoch: 33
[ Mon Jul 24 22:03:34 2023 ] 	Mean training loss: 0.8608.  Mean training acc: 74.50%.
[ Mon Jul 24 22:03:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 22:03:34 2023 ] Eval epoch: 33
[ Mon Jul 24 22:16:05 2023 ] 	Mean test loss of 796 batches: 1.1412585884632178.
[ Mon Jul 24 22:16:06 2023 ] 	Top1: 67.00%
[ Mon Jul 24 22:16:06 2023 ] 	Top5: 91.45%
[ Mon Jul 24 22:16:06 2023 ] Training epoch: 34
[ Mon Jul 24 22:46:15 2023 ] 	Mean training loss: 0.8630.  Mean training acc: 74.38%.
[ Mon Jul 24 22:46:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 22:46:15 2023 ] Eval epoch: 34
[ Mon Jul 24 22:58:41 2023 ] 	Mean test loss of 796 batches: 1.1451281760655456.
[ Mon Jul 24 22:58:41 2023 ] 	Top1: 67.35%
[ Mon Jul 24 22:58:42 2023 ] 	Top5: 91.25%
[ Mon Jul 24 22:58:42 2023 ] Training epoch: 35
[ Mon Jul 24 23:28:38 2023 ] 	Mean training loss: 0.8522.  Mean training acc: 74.94%.
[ Mon Jul 24 23:28:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Mon Jul 24 23:28:38 2023 ] Eval epoch: 35
[ Mon Jul 24 23:41:03 2023 ] 	Mean test loss of 796 batches: 1.290030314657257.
[ Mon Jul 24 23:41:04 2023 ] 	Top1: 63.54%
[ Mon Jul 24 23:41:04 2023 ] 	Top5: 88.40%
[ Mon Jul 24 23:41:04 2023 ] Training epoch: 36
[ Tue Jul 25 00:11:08 2023 ] 	Mean training loss: 0.5244.  Mean training acc: 84.39%.
[ Tue Jul 25 00:11:08 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 00:11:08 2023 ] Eval epoch: 36
[ Tue Jul 25 00:23:34 2023 ] 	Mean test loss of 796 batches: 0.6361119915174329.
[ Tue Jul 25 00:23:34 2023 ] 	Top1: 80.50%
[ Tue Jul 25 00:23:35 2023 ] 	Top5: 96.33%
[ Tue Jul 25 00:23:35 2023 ] Training epoch: 37
[ Tue Jul 25 00:53:35 2023 ] 	Mean training loss: 0.4287.  Mean training acc: 87.11%.
[ Tue Jul 25 00:53:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 00:53:36 2023 ] Eval epoch: 37
[ Tue Jul 25 01:06:00 2023 ] 	Mean test loss of 796 batches: 0.6303364783151066.
[ Tue Jul 25 01:06:00 2023 ] 	Top1: 80.90%
[ Tue Jul 25 01:06:01 2023 ] 	Top5: 96.40%
[ Tue Jul 25 01:06:01 2023 ] Training epoch: 38
[ Tue Jul 25 01:36:14 2023 ] 	Mean training loss: 0.3872.  Mean training acc: 88.37%.
[ Tue Jul 25 01:36:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 01:36:14 2023 ] Eval epoch: 38
[ Tue Jul 25 01:48:40 2023 ] 	Mean test loss of 796 batches: 0.6230624080565407.
[ Tue Jul 25 01:48:41 2023 ] 	Top1: 81.18%
[ Tue Jul 25 01:48:41 2023 ] 	Top5: 96.34%
[ Tue Jul 25 01:48:41 2023 ] Training epoch: 39
[ Tue Jul 25 02:18:59 2023 ] 	Mean training loss: 0.3619.  Mean training acc: 89.13%.
[ Tue Jul 25 02:18:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 02:18:59 2023 ] Eval epoch: 39
[ Tue Jul 25 02:31:24 2023 ] 	Mean test loss of 796 batches: 0.6263908769504808.
[ Tue Jul 25 02:31:25 2023 ] 	Top1: 81.21%
[ Tue Jul 25 02:31:25 2023 ] 	Top5: 96.42%
[ Tue Jul 25 02:31:25 2023 ] Training epoch: 40
[ Tue Jul 25 03:01:29 2023 ] 	Mean training loss: 0.3398.  Mean training acc: 89.77%.
[ Tue Jul 25 03:01:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 03:01:29 2023 ] Eval epoch: 40
[ Tue Jul 25 03:13:56 2023 ] 	Mean test loss of 796 batches: 0.6260604156022096.
[ Tue Jul 25 03:13:57 2023 ] 	Top1: 81.32%
[ Tue Jul 25 03:13:57 2023 ] 	Top5: 96.42%
[ Tue Jul 25 03:13:57 2023 ] Training epoch: 41
[ Tue Jul 25 03:43:59 2023 ] 	Mean training loss: 0.3180.  Mean training acc: 90.42%.
[ Tue Jul 25 03:43:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 03:44:00 2023 ] Eval epoch: 41
[ Tue Jul 25 03:56:24 2023 ] 	Mean test loss of 796 batches: 0.6672901276162072.
[ Tue Jul 25 03:56:24 2023 ] 	Top1: 80.74%
[ Tue Jul 25 03:56:25 2023 ] 	Top5: 96.08%
[ Tue Jul 25 03:56:25 2023 ] Training epoch: 42
[ Tue Jul 25 04:26:26 2023 ] 	Mean training loss: 0.3035.  Mean training acc: 90.93%.
[ Tue Jul 25 04:26:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 04:26:26 2023 ] Eval epoch: 42
[ Tue Jul 25 04:38:51 2023 ] 	Mean test loss of 796 batches: 0.6269569938730954.
[ Tue Jul 25 04:38:52 2023 ] 	Top1: 81.65%
[ Tue Jul 25 04:38:52 2023 ] 	Top5: 96.46%
[ Tue Jul 25 04:38:52 2023 ] Training epoch: 43
[ Tue Jul 25 05:08:49 2023 ] 	Mean training loss: 0.2935.  Mean training acc: 91.24%.
[ Tue Jul 25 05:08:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 05:08:50 2023 ] Eval epoch: 43
[ Tue Jul 25 05:21:17 2023 ] 	Mean test loss of 796 batches: 0.688085110951683.
[ Tue Jul 25 05:21:18 2023 ] 	Top1: 80.20%
[ Tue Jul 25 05:21:18 2023 ] 	Top5: 95.89%
[ Tue Jul 25 05:21:18 2023 ] Training epoch: 44
[ Tue Jul 25 05:51:21 2023 ] 	Mean training loss: 0.2862.  Mean training acc: 91.52%.
[ Tue Jul 25 05:51:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 05:51:21 2023 ] Eval epoch: 44
[ Tue Jul 25 06:03:47 2023 ] 	Mean test loss of 796 batches: 0.682573105690617.
[ Tue Jul 25 06:03:48 2023 ] 	Top1: 80.35%
[ Tue Jul 25 06:03:48 2023 ] 	Top5: 95.95%
[ Tue Jul 25 06:03:48 2023 ] Training epoch: 45
[ Tue Jul 25 06:33:56 2023 ] 	Mean training loss: 0.2742.  Mean training acc: 91.81%.
[ Tue Jul 25 06:33:56 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 06:33:56 2023 ] Eval epoch: 45
[ Tue Jul 25 06:46:24 2023 ] 	Mean test loss of 796 batches: 0.7167138693170931.
[ Tue Jul 25 06:46:24 2023 ] 	Top1: 79.75%
[ Tue Jul 25 06:46:25 2023 ] 	Top5: 95.73%
[ Tue Jul 25 06:46:25 2023 ] Training epoch: 46
[ Tue Jul 25 07:17:03 2023 ] 	Mean training loss: 0.2757.  Mean training acc: 91.74%.
[ Tue Jul 25 07:17:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 07:17:04 2023 ] Eval epoch: 46
[ Tue Jul 25 07:29:43 2023 ] 	Mean test loss of 796 batches: 0.7055874396321462.
[ Tue Jul 25 07:29:44 2023 ] 	Top1: 79.81%
[ Tue Jul 25 07:29:44 2023 ] 	Top5: 95.80%
[ Tue Jul 25 07:29:45 2023 ] Training epoch: 47
[ Tue Jul 25 08:00:17 2023 ] 	Mean training loss: 0.2715.  Mean training acc: 91.89%.
[ Tue Jul 25 08:00:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 08:00:17 2023 ] Eval epoch: 47
[ Tue Jul 25 08:12:49 2023 ] 	Mean test loss of 796 batches: 0.7627332202116748.
[ Tue Jul 25 08:12:49 2023 ] 	Top1: 79.43%
[ Tue Jul 25 08:12:50 2023 ] 	Top5: 95.57%
[ Tue Jul 25 08:12:50 2023 ] Training epoch: 48
[ Tue Jul 25 08:42:59 2023 ] 	Mean training loss: 0.2646.  Mean training acc: 92.19%.
[ Tue Jul 25 08:42:59 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 08:42:59 2023 ] Eval epoch: 48
[ Tue Jul 25 08:55:23 2023 ] 	Mean test loss of 796 batches: 0.7040740475245756.
[ Tue Jul 25 08:55:23 2023 ] 	Top1: 80.20%
[ Tue Jul 25 08:55:24 2023 ] 	Top5: 95.90%
[ Tue Jul 25 08:55:24 2023 ] Training epoch: 49
[ Tue Jul 25 09:25:33 2023 ] 	Mean training loss: 0.2631.  Mean training acc: 92.22%.
[ Tue Jul 25 09:25:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 09:25:33 2023 ] Eval epoch: 49
[ Tue Jul 25 09:37:55 2023 ] 	Mean test loss of 796 batches: 0.7154857086476369.
[ Tue Jul 25 09:37:55 2023 ] 	Top1: 79.67%
[ Tue Jul 25 09:37:56 2023 ] 	Top5: 95.78%
[ Tue Jul 25 09:37:56 2023 ] Training epoch: 50
[ Tue Jul 25 10:08:06 2023 ] 	Mean training loss: 0.2624.  Mean training acc: 92.34%.
[ Tue Jul 25 10:08:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 10:08:06 2023 ] Eval epoch: 50
[ Tue Jul 25 10:20:29 2023 ] 	Mean test loss of 796 batches: 0.7372035763072009.
[ Tue Jul 25 10:20:30 2023 ] 	Top1: 79.48%
[ Tue Jul 25 10:20:30 2023 ] 	Top5: 95.59%
[ Tue Jul 25 10:20:30 2023 ] Training epoch: 51
[ Tue Jul 25 10:50:42 2023 ] 	Mean training loss: 0.2638.  Mean training acc: 92.14%.
[ Tue Jul 25 10:50:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 10:50:42 2023 ] Eval epoch: 51
[ Tue Jul 25 11:03:02 2023 ] 	Mean test loss of 796 batches: 0.7685411168852044.
[ Tue Jul 25 11:03:02 2023 ] 	Top1: 79.22%
[ Tue Jul 25 11:03:03 2023 ] 	Top5: 95.53%
[ Tue Jul 25 11:03:03 2023 ] Training epoch: 52
[ Tue Jul 25 11:33:09 2023 ] 	Mean training loss: 0.2625.  Mean training acc: 92.24%.
[ Tue Jul 25 11:33:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 11:33:09 2023 ] Eval epoch: 52
[ Tue Jul 25 11:45:33 2023 ] 	Mean test loss of 796 batches: 0.747178661201767.
[ Tue Jul 25 11:45:33 2023 ] 	Top1: 79.42%
[ Tue Jul 25 11:45:33 2023 ] 	Top5: 95.28%
[ Tue Jul 25 11:45:34 2023 ] Training epoch: 53
[ Tue Jul 25 12:15:34 2023 ] 	Mean training loss: 0.2579.  Mean training acc: 92.48%.
[ Tue Jul 25 12:15:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 12:15:34 2023 ] Eval epoch: 53
[ Tue Jul 25 12:27:58 2023 ] 	Mean test loss of 796 batches: 0.7283667640751181.
[ Tue Jul 25 12:27:58 2023 ] 	Top1: 79.86%
[ Tue Jul 25 12:27:59 2023 ] 	Top5: 95.75%
[ Tue Jul 25 12:27:59 2023 ] Training epoch: 54
[ Tue Jul 25 12:58:11 2023 ] 	Mean training loss: 0.2586.  Mean training acc: 92.33%.
[ Tue Jul 25 12:58:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 12:58:11 2023 ] Eval epoch: 54
[ Tue Jul 25 13:10:34 2023 ] 	Mean test loss of 796 batches: 0.748552513987425.
[ Tue Jul 25 13:10:35 2023 ] 	Top1: 79.51%
[ Tue Jul 25 13:10:35 2023 ] 	Top5: 95.53%
[ Tue Jul 25 13:10:36 2023 ] Training epoch: 55
[ Tue Jul 25 13:40:45 2023 ] 	Mean training loss: 0.2604.  Mean training acc: 92.33%.
[ Tue Jul 25 13:40:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 13:40:45 2023 ] Eval epoch: 55
[ Tue Jul 25 13:53:08 2023 ] 	Mean test loss of 796 batches: 0.7878381746385864.
[ Tue Jul 25 13:53:08 2023 ] 	Top1: 78.88%
[ Tue Jul 25 13:53:09 2023 ] 	Top5: 95.41%
[ Tue Jul 25 13:53:09 2023 ] Training epoch: 56
[ Tue Jul 25 14:23:23 2023 ] 	Mean training loss: 0.1679.  Mean training acc: 95.44%.
[ Tue Jul 25 14:23:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 14:23:23 2023 ] Eval epoch: 56
[ Tue Jul 25 14:35:45 2023 ] 	Mean test loss of 796 batches: 0.670805254089997.
[ Tue Jul 25 14:35:46 2023 ] 	Top1: 81.75%
[ Tue Jul 25 14:35:46 2023 ] 	Top5: 96.21%
[ Tue Jul 25 14:35:46 2023 ] Training epoch: 57
[ Tue Jul 25 15:06:06 2023 ] 	Mean training loss: 0.1346.  Mean training acc: 96.52%.
[ Tue Jul 25 15:06:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 15:06:06 2023 ] Eval epoch: 57
[ Tue Jul 25 15:18:24 2023 ] 	Mean test loss of 796 batches: 0.6804164023087103.
[ Tue Jul 25 15:18:24 2023 ] 	Top1: 81.66%
[ Tue Jul 25 15:18:25 2023 ] 	Top5: 96.04%
[ Tue Jul 25 15:18:25 2023 ] Training epoch: 58
[ Tue Jul 25 15:48:33 2023 ] 	Mean training loss: 0.1198.  Mean training acc: 96.98%.
[ Tue Jul 25 15:48:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 15:48:33 2023 ] Eval epoch: 58
[ Tue Jul 25 16:00:50 2023 ] 	Mean test loss of 796 batches: 0.6894856870698569.
[ Tue Jul 25 16:00:51 2023 ] 	Top1: 81.55%
[ Tue Jul 25 16:00:51 2023 ] 	Top5: 96.11%
[ Tue Jul 25 16:00:51 2023 ] Training epoch: 59
[ Tue Jul 25 16:31:14 2023 ] 	Mean training loss: 0.1144.  Mean training acc: 97.17%.
[ Tue Jul 25 16:31:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 16:31:14 2023 ] Eval epoch: 59
[ Tue Jul 25 16:43:32 2023 ] 	Mean test loss of 796 batches: 0.6723547005211589.
[ Tue Jul 25 16:43:32 2023 ] 	Top1: 82.22%
[ Tue Jul 25 16:43:33 2023 ] 	Top5: 96.35%
[ Tue Jul 25 16:43:33 2023 ] Training epoch: 60
[ Tue Jul 25 17:13:41 2023 ] 	Mean training loss: 0.1054.  Mean training acc: 97.40%.
[ Tue Jul 25 17:13:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 17:13:41 2023 ] Eval epoch: 60
[ Tue Jul 25 17:25:56 2023 ] 	Mean test loss of 796 batches: 0.6747881575819835.
[ Tue Jul 25 17:25:56 2023 ] 	Top1: 82.30%
[ Tue Jul 25 17:25:57 2023 ] 	Top5: 96.30%
[ Tue Jul 25 17:25:57 2023 ] Training epoch: 61
[ Tue Jul 25 17:56:10 2023 ] 	Mean training loss: 0.1026.  Mean training acc: 97.55%.
[ Tue Jul 25 17:56:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 17:56:10 2023 ] Eval epoch: 61
[ Tue Jul 25 18:08:26 2023 ] 	Mean test loss of 796 batches: 0.6764326271549541.
[ Tue Jul 25 18:08:27 2023 ] 	Top1: 82.25%
[ Tue Jul 25 18:08:27 2023 ] 	Top5: 96.27%
[ Tue Jul 25 18:08:27 2023 ] Training epoch: 62
[ Tue Jul 25 18:38:47 2023 ] 	Mean training loss: 0.0957.  Mean training acc: 97.75%.
[ Tue Jul 25 18:38:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 18:38:47 2023 ] Eval epoch: 62
[ Tue Jul 25 18:51:07 2023 ] 	Mean test loss of 796 batches: 0.6821312634508364.
[ Tue Jul 25 18:51:08 2023 ] 	Top1: 82.30%
[ Tue Jul 25 18:51:08 2023 ] 	Top5: 96.28%
[ Tue Jul 25 18:51:08 2023 ] Training epoch: 63
[ Tue Jul 25 19:21:13 2023 ] 	Mean training loss: 0.0943.  Mean training acc: 97.79%.
[ Tue Jul 25 19:21:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 19:21:14 2023 ] Eval epoch: 63
[ Tue Jul 25 19:33:31 2023 ] 	Mean test loss of 796 batches: 0.6942500846282621.
[ Tue Jul 25 19:33:32 2023 ] 	Top1: 82.07%
[ Tue Jul 25 19:33:32 2023 ] 	Top5: 96.06%
[ Tue Jul 25 19:33:32 2023 ] Training epoch: 64
[ Tue Jul 25 20:03:44 2023 ] 	Mean training loss: 0.0924.  Mean training acc: 97.81%.
[ Tue Jul 25 20:03:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 20:03:44 2023 ] Eval epoch: 64
[ Tue Jul 25 20:16:07 2023 ] 	Mean test loss of 796 batches: 0.6830671798793515.
[ Tue Jul 25 20:16:07 2023 ] 	Top1: 82.24%
[ Tue Jul 25 20:16:08 2023 ] 	Top5: 96.30%
[ Tue Jul 25 20:16:08 2023 ] Training epoch: 65
[ Tue Jul 25 20:46:14 2023 ] 	Mean training loss: 0.0875.  Mean training acc: 98.00%.
[ Tue Jul 25 20:46:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 20:46:15 2023 ] Eval epoch: 65
[ Tue Jul 25 20:58:35 2023 ] 	Mean test loss of 796 batches: 0.7019682459477055.
[ Tue Jul 25 20:58:35 2023 ] 	Top1: 82.24%
[ Tue Jul 25 20:58:36 2023 ] 	Top5: 96.12%
[ Tue Jul 25 20:58:36 2023 ] Training epoch: 66
[ Tue Jul 25 21:28:44 2023 ] 	Mean training loss: 0.0853.  Mean training acc: 98.03%.
[ Tue Jul 25 21:28:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 21:28:44 2023 ] Eval epoch: 66
[ Tue Jul 25 21:41:04 2023 ] 	Mean test loss of 796 batches: 0.6945188115608303.
[ Tue Jul 25 21:41:04 2023 ] 	Top1: 82.09%
[ Tue Jul 25 21:41:05 2023 ] 	Top5: 96.12%
[ Tue Jul 25 21:41:05 2023 ] Training epoch: 67
[ Tue Jul 25 22:11:22 2023 ] 	Mean training loss: 0.0833.  Mean training acc: 98.13%.
[ Tue Jul 25 22:11:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 22:11:22 2023 ] Eval epoch: 67
[ Tue Jul 25 22:23:40 2023 ] 	Mean test loss of 796 batches: 0.7001763709338765.
[ Tue Jul 25 22:23:41 2023 ] 	Top1: 82.01%
[ Tue Jul 25 22:23:41 2023 ] 	Top5: 96.15%
[ Tue Jul 25 22:23:41 2023 ] Training epoch: 68
[ Tue Jul 25 22:53:44 2023 ] 	Mean training loss: 0.0812.  Mean training acc: 98.22%.
[ Tue Jul 25 22:53:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 22:53:44 2023 ] Eval epoch: 68
[ Tue Jul 25 23:06:05 2023 ] 	Mean test loss of 796 batches: 0.7114472700442052.
[ Tue Jul 25 23:06:05 2023 ] 	Top1: 81.79%
[ Tue Jul 25 23:06:06 2023 ] 	Top5: 96.02%
[ Tue Jul 25 23:06:06 2023 ] Training epoch: 69
[ Tue Jul 25 23:36:13 2023 ] 	Mean training loss: 0.0793.  Mean training acc: 98.24%.
[ Tue Jul 25 23:36:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 25 23:36:13 2023 ] Eval epoch: 69
[ Tue Jul 25 23:48:32 2023 ] 	Mean test loss of 796 batches: 0.7063532088831741.
[ Tue Jul 25 23:48:32 2023 ] 	Top1: 81.96%
[ Tue Jul 25 23:48:33 2023 ] 	Top5: 96.09%
[ Tue Jul 25 23:48:33 2023 ] Training epoch: 70
[ Wed Jul 26 00:18:49 2023 ] 	Mean training loss: 0.0796.  Mean training acc: 98.20%.
[ Wed Jul 26 00:18:49 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 00:18:49 2023 ] Eval epoch: 70
[ Wed Jul 26 00:31:45 2023 ] 	Mean test loss of 796 batches: 0.7109868752690566.
[ Wed Jul 26 00:31:46 2023 ] 	Top1: 82.09%
[ Wed Jul 26 00:31:46 2023 ] 	Top5: 96.10%
[ Wed Jul 26 00:31:47 2023 ] Training epoch: 71
[ Wed Jul 26 01:03:45 2023 ] 	Mean training loss: 0.0746.  Mean training acc: 98.40%.
[ Wed Jul 26 01:03:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 01:03:46 2023 ] Eval epoch: 71
[ Wed Jul 26 01:16:49 2023 ] 	Mean test loss of 796 batches: 0.7045338980610197.
[ Wed Jul 26 01:16:49 2023 ] 	Top1: 82.23%
[ Wed Jul 26 01:16:50 2023 ] 	Top5: 96.19%
[ Wed Jul 26 01:16:50 2023 ] Training epoch: 72
[ Wed Jul 26 01:48:44 2023 ] 	Mean training loss: 0.0743.  Mean training acc: 98.38%.
[ Wed Jul 26 01:48:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 01:48:45 2023 ] Eval epoch: 72
[ Wed Jul 26 02:01:37 2023 ] 	Mean test loss of 796 batches: 0.7074080069816142.
[ Wed Jul 26 02:01:38 2023 ] 	Top1: 82.14%
[ Wed Jul 26 02:01:38 2023 ] 	Top5: 96.05%
[ Wed Jul 26 02:01:38 2023 ] Training epoch: 73
[ Wed Jul 26 02:33:30 2023 ] 	Mean training loss: 0.0714.  Mean training acc: 98.47%.
[ Wed Jul 26 02:33:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 02:33:31 2023 ] Eval epoch: 73
[ Wed Jul 26 02:46:35 2023 ] 	Mean test loss of 796 batches: 0.6961304422598987.
[ Wed Jul 26 02:46:36 2023 ] 	Top1: 82.31%
[ Wed Jul 26 02:46:36 2023 ] 	Top5: 96.15%
[ Wed Jul 26 02:46:36 2023 ] Training epoch: 74
[ Wed Jul 26 03:18:30 2023 ] 	Mean training loss: 0.0717.  Mean training acc: 98.46%.
[ Wed Jul 26 03:18:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 03:18:30 2023 ] Eval epoch: 74
[ Wed Jul 26 03:31:42 2023 ] 	Mean test loss of 796 batches: 0.708236009359884.
[ Wed Jul 26 03:31:43 2023 ] 	Top1: 82.20%
[ Wed Jul 26 03:31:43 2023 ] 	Top5: 96.13%
[ Wed Jul 26 03:31:44 2023 ] Training epoch: 75
[ Wed Jul 26 04:03:29 2023 ] 	Mean training loss: 0.0711.  Mean training acc: 98.47%.
[ Wed Jul 26 04:03:29 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 04:03:29 2023 ] Eval epoch: 75
[ Wed Jul 26 04:16:36 2023 ] 	Mean test loss of 796 batches: 0.719908106360753.
[ Wed Jul 26 04:16:36 2023 ] 	Top1: 81.84%
[ Wed Jul 26 04:16:36 2023 ] 	Top5: 96.02%
[ Wed Jul 26 04:16:37 2023 ] Training epoch: 76
[ Wed Jul 26 04:48:22 2023 ] 	Mean training loss: 0.0668.  Mean training acc: 98.62%.
[ Wed Jul 26 04:48:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 04:48:22 2023 ] Eval epoch: 76
[ Wed Jul 26 05:01:36 2023 ] 	Mean test loss of 796 batches: 0.7297591597646774.
[ Wed Jul 26 05:01:37 2023 ] 	Top1: 81.46%
[ Wed Jul 26 05:01:37 2023 ] 	Top5: 95.98%
[ Wed Jul 26 05:01:37 2023 ] Training epoch: 77
[ Wed Jul 26 05:33:10 2023 ] 	Mean training loss: 0.0643.  Mean training acc: 98.70%.
[ Wed Jul 26 05:33:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 05:33:10 2023 ] Eval epoch: 77
[ Wed Jul 26 05:46:18 2023 ] 	Mean test loss of 796 batches: 0.7153326032599013.
[ Wed Jul 26 05:46:18 2023 ] 	Top1: 81.88%
[ Wed Jul 26 05:46:19 2023 ] 	Top5: 95.98%
[ Wed Jul 26 05:46:19 2023 ] Training epoch: 78
[ Wed Jul 26 06:18:10 2023 ] 	Mean training loss: 0.0642.  Mean training acc: 98.69%.
[ Wed Jul 26 06:18:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 06:18:10 2023 ] Eval epoch: 78
[ Wed Jul 26 06:31:18 2023 ] 	Mean test loss of 796 batches: 0.708745745361675.
[ Wed Jul 26 06:31:19 2023 ] 	Top1: 81.96%
[ Wed Jul 26 06:31:19 2023 ] 	Top5: 96.15%
[ Wed Jul 26 06:31:19 2023 ] Training epoch: 79
[ Wed Jul 26 07:03:14 2023 ] 	Mean training loss: 0.0630.  Mean training acc: 98.72%.
[ Wed Jul 26 07:03:14 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 07:03:15 2023 ] Eval epoch: 79
[ Wed Jul 26 07:16:21 2023 ] 	Mean test loss of 796 batches: 0.7486893533349935.
[ Wed Jul 26 07:16:22 2023 ] 	Top1: 82.18%
[ Wed Jul 26 07:16:22 2023 ] 	Top5: 96.03%
[ Wed Jul 26 07:16:22 2023 ] Training epoch: 80
[ Wed Jul 26 07:48:23 2023 ] 	Mean training loss: 0.0619.  Mean training acc: 98.76%.
[ Wed Jul 26 07:48:24 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 07:48:24 2023 ] Eval epoch: 80
[ Wed Jul 26 08:01:25 2023 ] 	Mean test loss of 796 batches: 0.7035427810764642.
[ Wed Jul 26 08:01:26 2023 ] 	Top1: 82.31%
[ Wed Jul 26 08:01:26 2023 ] 	Top5: 96.14%
[ Wed Jul 26 08:01:27 2023 ] Training epoch: 81
[ Wed Jul 26 08:33:31 2023 ] 	Mean training loss: 0.0621.  Mean training acc: 98.81%.
[ Wed Jul 26 08:33:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 08:33:31 2023 ] Eval epoch: 81
[ Wed Jul 26 08:46:30 2023 ] 	Mean test loss of 796 batches: 0.7202360632843409.
[ Wed Jul 26 08:46:31 2023 ] 	Top1: 81.83%
[ Wed Jul 26 08:46:31 2023 ] 	Top5: 95.98%
[ Wed Jul 26 08:46:32 2023 ] Training epoch: 82
[ Wed Jul 26 09:18:27 2023 ] 	Mean training loss: 0.0596.  Mean training acc: 98.84%.
[ Wed Jul 26 09:18:27 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 09:18:28 2023 ] Eval epoch: 82
[ Wed Jul 26 09:31:22 2023 ] 	Mean test loss of 796 batches: 0.7094892576224541.
[ Wed Jul 26 09:31:23 2023 ] 	Top1: 82.12%
[ Wed Jul 26 09:31:23 2023 ] 	Top5: 96.06%
[ Wed Jul 26 09:31:23 2023 ] Training epoch: 83
[ Wed Jul 26 10:03:22 2023 ] 	Mean training loss: 0.0603.  Mean training acc: 98.80%.
[ Wed Jul 26 10:03:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 10:03:22 2023 ] Eval epoch: 83
[ Wed Jul 26 10:16:30 2023 ] 	Mean test loss of 796 batches: 0.733923454885956.
[ Wed Jul 26 10:16:31 2023 ] 	Top1: 82.07%
[ Wed Jul 26 10:16:31 2023 ] 	Top5: 96.02%
[ Wed Jul 26 10:16:31 2023 ] Training epoch: 84
[ Wed Jul 26 10:48:31 2023 ] 	Mean training loss: 0.0601.  Mean training acc: 98.81%.
[ Wed Jul 26 10:48:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 10:48:31 2023 ] Eval epoch: 84
[ Wed Jul 26 11:01:52 2023 ] 	Mean test loss of 796 batches: 0.7139929967122761.
[ Wed Jul 26 11:01:53 2023 ] 	Top1: 81.99%
[ Wed Jul 26 11:01:53 2023 ] 	Top5: 96.07%
[ Wed Jul 26 11:01:53 2023 ] Training epoch: 85
[ Wed Jul 26 11:34:30 2023 ] 	Mean training loss: 0.0605.  Mean training acc: 98.82%.
[ Wed Jul 26 11:34:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 26 11:34:30 2023 ] Eval epoch: 85
[ Wed Jul 26 11:48:01 2023 ] 	Mean test loss of 796 batches: 0.7220174752026047.
[ Wed Jul 26 11:48:02 2023 ] 	Top1: 81.71%
[ Wed Jul 26 11:48:02 2023 ] 	Top5: 95.96%
[ Wed Jul 26 12:01:33 2023 ] Best accuracy: 0.8231112158526287
[ Wed Jul 26 12:01:33 2023 ] Epoch number: 80
[ Wed Jul 26 12:01:33 2023 ] Model name: train/ntu120/xsub/multihead3tanh_ctrgcn_bone_motion
[ Wed Jul 26 12:01:33 2023 ] Model total number of params: 1745788
[ Wed Jul 26 12:01:33 2023 ] Weight decay: 0.0004
[ Wed Jul 26 12:01:33 2023 ] Base LR: 0.1
[ Wed Jul 26 12:01:33 2023 ] Batch Size: 64
[ Wed Jul 26 12:01:33 2023 ] Test Batch Size: 64
[ Wed Jul 26 12:01:34 2023 ] seed: 1
