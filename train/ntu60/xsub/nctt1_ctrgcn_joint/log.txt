[ Tue Jul 11 05:03:44 2023 ] Load weights from /21085401076/pretrained_model/pretrained_model/NTU60_Xsub/CTRGCN_joint_89.9/runs-60-37560.pt.
[ Tue Jul 11 05:03:48 2023 ] using warm up, epoch: 5
[ Tue Jul 11 05:04:07 2023 ] Parameters:
{'work_dir': 'train/ntu60/xsub/nctt1_ctrgcn_joint', 'model_saved_name': 'train/ntu60/xsub/nctt1_ctrgcn_joint/runs', 'config': 'config/nturgbd-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': '/21085401076/data/home/sdc1/dy/CTR-GCN-main/CTR-GCN-main/data/ntu/NTU60_CS.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': '/21085401076/data/home/sdc1/dy/CTR-GCN-main/CTR-GCN-main/data/ntu/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.ctrgcn.Model', 'model_args': {'num_class': 60, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': '/21085401076/pretrained_model/pretrained_model/NTU60_Xsub/CTRGCN_joint_89.9/runs-60-37560.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55, 75], 'device': [0, 1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 85, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jul 11 05:04:07 2023 ] # Parameters: 1731776
[ Tue Jul 11 05:04:07 2023 ] Training epoch: 1
[ Tue Jul 11 05:23:23 2023 ] 	Mean training loss: 0.6065.  Mean training acc: 81.49%.
[ Tue Jul 11 05:23:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 05:23:23 2023 ] Eval epoch: 1
[ Tue Jul 11 05:27:31 2023 ] 	Mean test loss of 258 batches: 0.5115230846428132.
[ Tue Jul 11 05:27:31 2023 ] 	Top1: 84.66%
[ Tue Jul 11 05:27:31 2023 ] 	Top5: 97.60%
[ Tue Jul 11 05:27:31 2023 ] Training epoch: 2
[ Tue Jul 11 05:46:20 2023 ] 	Mean training loss: 0.5184.  Mean training acc: 83.59%.
[ Tue Jul 11 05:46:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 05:46:20 2023 ] Eval epoch: 2
[ Tue Jul 11 05:50:32 2023 ] 	Mean test loss of 258 batches: 0.6035471269211103.
[ Tue Jul 11 05:50:32 2023 ] 	Top1: 82.25%
[ Tue Jul 11 05:50:33 2023 ] 	Top5: 96.99%
[ Tue Jul 11 05:50:33 2023 ] Training epoch: 3
[ Tue Jul 11 06:09:35 2023 ] 	Mean training loss: 0.5396.  Mean training acc: 82.96%.
[ Tue Jul 11 06:09:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 06:09:35 2023 ] Eval epoch: 3
[ Tue Jul 11 06:13:41 2023 ] 	Mean test loss of 258 batches: 0.6004126433485238.
[ Tue Jul 11 06:13:41 2023 ] 	Top1: 81.15%
[ Tue Jul 11 06:13:42 2023 ] 	Top5: 97.05%
[ Tue Jul 11 06:13:42 2023 ] Training epoch: 4
[ Tue Jul 11 06:32:38 2023 ] 	Mean training loss: 0.5586.  Mean training acc: 82.46%.
[ Tue Jul 11 06:32:38 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 06:32:38 2023 ] Eval epoch: 4
[ Tue Jul 11 06:36:41 2023 ] 	Mean test loss of 258 batches: 0.6629984057111333.
[ Tue Jul 11 06:36:41 2023 ] 	Top1: 79.84%
[ Tue Jul 11 06:36:41 2023 ] 	Top5: 96.68%
[ Tue Jul 11 06:36:41 2023 ] Training epoch: 5
[ Tue Jul 11 06:55:46 2023 ] 	Mean training loss: 0.5827.  Mean training acc: 81.84%.
[ Tue Jul 11 06:55:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 06:55:46 2023 ] Eval epoch: 5
[ Tue Jul 11 06:59:52 2023 ] 	Mean test loss of 258 batches: 0.6433309810452683.
[ Tue Jul 11 06:59:52 2023 ] 	Top1: 80.47%
[ Tue Jul 11 06:59:52 2023 ] 	Top5: 96.68%
[ Tue Jul 11 06:59:52 2023 ] Training epoch: 6
[ Tue Jul 11 07:18:44 2023 ] 	Mean training loss: 0.5613.  Mean training acc: 82.22%.
[ Tue Jul 11 07:18:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 07:18:44 2023 ] Eval epoch: 6
[ Tue Jul 11 07:22:47 2023 ] 	Mean test loss of 258 batches: 0.7999623894922493.
[ Tue Jul 11 07:22:47 2023 ] 	Top1: 76.79%
[ Tue Jul 11 07:22:47 2023 ] 	Top5: 95.85%
[ Tue Jul 11 07:22:47 2023 ] Training epoch: 7
[ Tue Jul 11 07:41:31 2023 ] 	Mean training loss: 0.5402.  Mean training acc: 83.19%.
[ Tue Jul 11 07:41:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 07:41:31 2023 ] Eval epoch: 7
[ Tue Jul 11 07:45:33 2023 ] 	Mean test loss of 258 batches: 0.6705353181491527.
[ Tue Jul 11 07:45:34 2023 ] 	Top1: 80.01%
[ Tue Jul 11 07:45:34 2023 ] 	Top5: 96.42%
[ Tue Jul 11 07:45:34 2023 ] Training epoch: 8
[ Tue Jul 11 08:04:20 2023 ] 	Mean training loss: 0.5358.  Mean training acc: 83.16%.
[ Tue Jul 11 08:04:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 08:04:20 2023 ] Eval epoch: 8
[ Tue Jul 11 08:08:24 2023 ] 	Mean test loss of 258 batches: 0.8050731058384097.
[ Tue Jul 11 08:08:24 2023 ] 	Top1: 77.97%
[ Tue Jul 11 08:08:24 2023 ] 	Top5: 96.17%
[ Tue Jul 11 08:08:24 2023 ] Training epoch: 9
[ Tue Jul 11 08:27:16 2023 ] 	Mean training loss: 0.5365.  Mean training acc: 83.10%.
[ Tue Jul 11 08:27:16 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 08:27:16 2023 ] Eval epoch: 9
[ Tue Jul 11 08:31:19 2023 ] 	Mean test loss of 258 batches: 0.6793275615272596.
[ Tue Jul 11 08:31:20 2023 ] 	Top1: 80.03%
[ Tue Jul 11 08:31:20 2023 ] 	Top5: 96.12%
[ Tue Jul 11 08:31:20 2023 ] Training epoch: 10
[ Tue Jul 11 08:50:10 2023 ] 	Mean training loss: 0.5308.  Mean training acc: 83.21%.
[ Tue Jul 11 08:50:10 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 08:50:10 2023 ] Eval epoch: 10
[ Tue Jul 11 08:54:13 2023 ] 	Mean test loss of 258 batches: 0.689568329342576.
[ Tue Jul 11 08:54:13 2023 ] 	Top1: 78.97%
[ Tue Jul 11 08:54:13 2023 ] 	Top5: 95.95%
[ Tue Jul 11 08:54:13 2023 ] Training epoch: 11
[ Tue Jul 11 09:13:04 2023 ] 	Mean training loss: 0.5235.  Mean training acc: 83.50%.
[ Tue Jul 11 09:13:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 09:13:04 2023 ] Eval epoch: 11
[ Tue Jul 11 09:17:07 2023 ] 	Mean test loss of 258 batches: 1.1186405345219974.
[ Tue Jul 11 09:17:07 2023 ] 	Top1: 70.33%
[ Tue Jul 11 09:17:07 2023 ] 	Top5: 93.04%
[ Tue Jul 11 09:17:07 2023 ] Training epoch: 12
[ Tue Jul 11 09:35:50 2023 ] 	Mean training loss: 0.5309.  Mean training acc: 83.20%.
[ Tue Jul 11 09:35:50 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 09:35:50 2023 ] Eval epoch: 12
[ Tue Jul 11 09:39:52 2023 ] 	Mean test loss of 258 batches: 0.6480593484385994.
[ Tue Jul 11 09:39:53 2023 ] 	Top1: 80.17%
[ Tue Jul 11 09:39:53 2023 ] 	Top5: 96.58%
[ Tue Jul 11 09:39:53 2023 ] Training epoch: 13
[ Tue Jul 11 09:58:31 2023 ] 	Mean training loss: 0.5244.  Mean training acc: 83.47%.
[ Tue Jul 11 09:58:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 09:58:31 2023 ] Eval epoch: 13
[ Tue Jul 11 10:02:34 2023 ] 	Mean test loss of 258 batches: 0.6214713242280391.
[ Tue Jul 11 10:02:34 2023 ] 	Top1: 80.81%
[ Tue Jul 11 10:02:34 2023 ] 	Top5: 96.72%
[ Tue Jul 11 10:02:34 2023 ] Training epoch: 14
[ Tue Jul 11 10:21:18 2023 ] 	Mean training loss: 0.5268.  Mean training acc: 83.35%.
[ Tue Jul 11 10:21:18 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 10:21:18 2023 ] Eval epoch: 14
[ Tue Jul 11 10:25:20 2023 ] 	Mean test loss of 258 batches: 0.6739385677284973.
[ Tue Jul 11 10:25:20 2023 ] 	Top1: 79.58%
[ Tue Jul 11 10:25:21 2023 ] 	Top5: 96.54%
[ Tue Jul 11 10:25:21 2023 ] Training epoch: 15
[ Tue Jul 11 10:44:01 2023 ] 	Mean training loss: 0.5186.  Mean training acc: 83.58%.
[ Tue Jul 11 10:44:01 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 10:44:01 2023 ] Eval epoch: 15
[ Tue Jul 11 10:48:03 2023 ] 	Mean test loss of 258 batches: 0.7131674947549206.
[ Tue Jul 11 10:48:03 2023 ] 	Top1: 79.07%
[ Tue Jul 11 10:48:03 2023 ] 	Top5: 96.58%
[ Tue Jul 11 10:48:03 2023 ] Training epoch: 16
[ Tue Jul 11 11:06:45 2023 ] 	Mean training loss: 0.5179.  Mean training acc: 83.62%.
[ Tue Jul 11 11:06:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 11:06:45 2023 ] Eval epoch: 16
[ Tue Jul 11 11:10:47 2023 ] 	Mean test loss of 258 batches: 0.6084014942017637.
[ Tue Jul 11 11:10:47 2023 ] 	Top1: 82.11%
[ Tue Jul 11 11:10:47 2023 ] 	Top5: 96.71%
[ Tue Jul 11 11:10:47 2023 ] Training epoch: 17
[ Tue Jul 11 11:29:31 2023 ] 	Mean training loss: 0.5157.  Mean training acc: 83.91%.
[ Tue Jul 11 11:29:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 11:29:31 2023 ] Eval epoch: 17
[ Tue Jul 11 11:33:33 2023 ] 	Mean test loss of 258 batches: 0.9200735194969547.
[ Tue Jul 11 11:33:33 2023 ] 	Top1: 74.58%
[ Tue Jul 11 11:33:33 2023 ] 	Top5: 94.33%
[ Tue Jul 11 11:33:33 2023 ] Training epoch: 18
[ Tue Jul 11 11:52:17 2023 ] 	Mean training loss: 0.5111.  Mean training acc: 83.92%.
[ Tue Jul 11 11:52:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 11:52:17 2023 ] Eval epoch: 18
[ Tue Jul 11 11:56:20 2023 ] 	Mean test loss of 258 batches: 0.9971444218657738.
[ Tue Jul 11 11:56:20 2023 ] 	Top1: 73.22%
[ Tue Jul 11 11:56:20 2023 ] 	Top5: 93.59%
[ Tue Jul 11 11:56:20 2023 ] Training epoch: 19
[ Tue Jul 11 12:15:06 2023 ] 	Mean training loss: 0.5197.  Mean training acc: 83.63%.
[ Tue Jul 11 12:15:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 12:15:06 2023 ] Eval epoch: 19
[ Tue Jul 11 12:19:08 2023 ] 	Mean test loss of 258 batches: 0.8412343658680139.
[ Tue Jul 11 12:19:08 2023 ] 	Top1: 77.08%
[ Tue Jul 11 12:19:09 2023 ] 	Top5: 94.06%
[ Tue Jul 11 12:19:09 2023 ] Training epoch: 20
[ Tue Jul 11 12:37:54 2023 ] 	Mean training loss: 0.5121.  Mean training acc: 83.88%.
[ Tue Jul 11 12:37:54 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 12:37:54 2023 ] Eval epoch: 20
[ Tue Jul 11 12:41:57 2023 ] 	Mean test loss of 258 batches: 0.9180770856003428.
[ Tue Jul 11 12:41:57 2023 ] 	Top1: 74.66%
[ Tue Jul 11 12:41:57 2023 ] 	Top5: 94.24%
[ Tue Jul 11 12:41:57 2023 ] Training epoch: 21
[ Tue Jul 11 13:00:48 2023 ] 	Mean training loss: 0.5106.  Mean training acc: 83.66%.
[ Tue Jul 11 13:00:48 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 13:00:48 2023 ] Eval epoch: 21
[ Tue Jul 11 13:04:51 2023 ] 	Mean test loss of 258 batches: 1.1275387618892876.
[ Tue Jul 11 13:04:51 2023 ] 	Top1: 71.18%
[ Tue Jul 11 13:04:51 2023 ] 	Top5: 92.44%
[ Tue Jul 11 13:04:51 2023 ] Training epoch: 22
[ Tue Jul 11 13:23:41 2023 ] 	Mean training loss: 0.5020.  Mean training acc: 84.17%.
[ Tue Jul 11 13:23:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 13:23:41 2023 ] Eval epoch: 22
[ Tue Jul 11 13:27:45 2023 ] 	Mean test loss of 258 batches: 0.6406726328901542.
[ Tue Jul 11 13:27:45 2023 ] 	Top1: 81.58%
[ Tue Jul 11 13:27:45 2023 ] 	Top5: 96.46%
[ Tue Jul 11 13:27:45 2023 ] Training epoch: 23
[ Tue Jul 11 13:46:27 2023 ] 	Mean training loss: 0.5045.  Mean training acc: 84.21%.
[ Tue Jul 11 13:46:27 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 13:46:27 2023 ] Eval epoch: 23
[ Tue Jul 11 13:50:30 2023 ] 	Mean test loss of 258 batches: 0.7425645843090475.
[ Tue Jul 11 13:50:30 2023 ] 	Top1: 78.43%
[ Tue Jul 11 13:50:30 2023 ] 	Top5: 96.30%
[ Tue Jul 11 13:50:30 2023 ] Training epoch: 24
[ Tue Jul 11 14:09:17 2023 ] 	Mean training loss: 0.4996.  Mean training acc: 84.17%.
[ Tue Jul 11 14:09:17 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 14:09:17 2023 ] Eval epoch: 24
[ Tue Jul 11 14:13:20 2023 ] 	Mean test loss of 258 batches: 0.6073151903674584.
[ Tue Jul 11 14:13:20 2023 ] 	Top1: 81.96%
[ Tue Jul 11 14:13:20 2023 ] 	Top5: 96.82%
[ Tue Jul 11 14:13:21 2023 ] Training epoch: 25
[ Tue Jul 11 14:32:13 2023 ] 	Mean training loss: 0.5095.  Mean training acc: 83.87%.
[ Tue Jul 11 14:32:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 14:32:13 2023 ] Eval epoch: 25
[ Tue Jul 11 14:36:17 2023 ] 	Mean test loss of 258 batches: 2.974604999834253.
[ Tue Jul 11 14:36:17 2023 ] 	Top1: 51.60%
[ Tue Jul 11 14:36:17 2023 ] 	Top5: 78.52%
[ Tue Jul 11 14:36:17 2023 ] Training epoch: 26
[ Tue Jul 11 14:55:11 2023 ] 	Mean training loss: 0.5043.  Mean training acc: 84.07%.
[ Tue Jul 11 14:55:11 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 14:55:11 2023 ] Eval epoch: 26
[ Tue Jul 11 14:59:14 2023 ] 	Mean test loss of 258 batches: 0.5858005386914393.
[ Tue Jul 11 14:59:15 2023 ] 	Top1: 82.51%
[ Tue Jul 11 14:59:15 2023 ] 	Top5: 96.94%
[ Tue Jul 11 14:59:15 2023 ] Training epoch: 27
[ Tue Jul 11 15:17:58 2023 ] 	Mean training loss: 0.4984.  Mean training acc: 84.06%.
[ Tue Jul 11 15:17:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 15:17:59 2023 ] Eval epoch: 27
[ Tue Jul 11 15:22:02 2023 ] 	Mean test loss of 258 batches: 0.8260326539130174.
[ Tue Jul 11 15:22:02 2023 ] 	Top1: 75.85%
[ Tue Jul 11 15:22:02 2023 ] 	Top5: 95.92%
[ Tue Jul 11 15:22:02 2023 ] Training epoch: 28
[ Tue Jul 11 15:40:52 2023 ] 	Mean training loss: 0.5039.  Mean training acc: 83.96%.
[ Tue Jul 11 15:40:52 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 15:40:52 2023 ] Eval epoch: 28
[ Tue Jul 11 15:44:56 2023 ] 	Mean test loss of 258 batches: 0.6428682656828747.
[ Tue Jul 11 15:44:56 2023 ] 	Top1: 81.14%
[ Tue Jul 11 15:44:57 2023 ] 	Top5: 96.54%
[ Tue Jul 11 15:44:57 2023 ] Training epoch: 29
[ Tue Jul 11 16:03:45 2023 ] 	Mean training loss: 0.4963.  Mean training acc: 84.42%.
[ Tue Jul 11 16:03:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 16:03:45 2023 ] Eval epoch: 29
[ Tue Jul 11 16:07:50 2023 ] 	Mean test loss of 258 batches: 0.639564975922884.
[ Tue Jul 11 16:07:50 2023 ] 	Top1: 81.39%
[ Tue Jul 11 16:07:50 2023 ] 	Top5: 96.59%
[ Tue Jul 11 16:07:50 2023 ] Training epoch: 30
[ Tue Jul 11 16:26:44 2023 ] 	Mean training loss: 0.4994.  Mean training acc: 84.19%.
[ Tue Jul 11 16:26:44 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 16:26:44 2023 ] Eval epoch: 30
[ Tue Jul 11 16:30:49 2023 ] 	Mean test loss of 258 batches: 1.1635955443909003.
[ Tue Jul 11 16:30:49 2023 ] 	Top1: 71.10%
[ Tue Jul 11 16:30:49 2023 ] 	Top5: 92.82%
[ Tue Jul 11 16:30:49 2023 ] Training epoch: 31
[ Tue Jul 11 16:49:31 2023 ] 	Mean training loss: 0.4987.  Mean training acc: 84.22%.
[ Tue Jul 11 16:49:31 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 16:49:31 2023 ] Eval epoch: 31
[ Tue Jul 11 16:53:35 2023 ] 	Mean test loss of 258 batches: 0.7602531603833501.
[ Tue Jul 11 16:53:35 2023 ] 	Top1: 78.19%
[ Tue Jul 11 16:53:35 2023 ] 	Top5: 96.08%
[ Tue Jul 11 16:53:35 2023 ] Training epoch: 32
[ Tue Jul 11 17:12:21 2023 ] 	Mean training loss: 0.4979.  Mean training acc: 84.38%.
[ Tue Jul 11 17:12:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 17:12:22 2023 ] Eval epoch: 32
[ Tue Jul 11 17:16:26 2023 ] 	Mean test loss of 258 batches: 0.9651750084734703.
[ Tue Jul 11 17:16:26 2023 ] 	Top1: 73.32%
[ Tue Jul 11 17:16:27 2023 ] 	Top5: 94.35%
[ Tue Jul 11 17:16:27 2023 ] Training epoch: 33
[ Tue Jul 11 17:35:13 2023 ] 	Mean training loss: 0.4949.  Mean training acc: 84.30%.
[ Tue Jul 11 17:35:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 17:35:13 2023 ] Eval epoch: 33
[ Tue Jul 11 17:39:15 2023 ] 	Mean test loss of 258 batches: 0.680084422288477.
[ Tue Jul 11 17:39:16 2023 ] 	Top1: 79.58%
[ Tue Jul 11 17:39:16 2023 ] 	Top5: 96.26%
[ Tue Jul 11 17:39:16 2023 ] Training epoch: 34
[ Tue Jul 11 17:58:07 2023 ] 	Mean training loss: 0.4921.  Mean training acc: 84.32%.
[ Tue Jul 11 17:58:07 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 17:58:08 2023 ] Eval epoch: 34
[ Tue Jul 11 18:02:11 2023 ] 	Mean test loss of 258 batches: 0.720668093640675.
[ Tue Jul 11 18:02:11 2023 ] 	Top1: 79.76%
[ Tue Jul 11 18:02:11 2023 ] 	Top5: 96.04%
[ Tue Jul 11 18:02:11 2023 ] Training epoch: 35
[ Tue Jul 11 18:21:04 2023 ] 	Mean training loss: 0.4889.  Mean training acc: 84.48%.
[ Tue Jul 11 18:21:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 18:21:05 2023 ] Eval epoch: 35
[ Tue Jul 11 18:25:09 2023 ] 	Mean test loss of 258 batches: 0.6414210941324863.
[ Tue Jul 11 18:25:09 2023 ] 	Top1: 81.93%
[ Tue Jul 11 18:25:09 2023 ] 	Top5: 96.62%
[ Tue Jul 11 18:25:10 2023 ] Training epoch: 36
[ Tue Jul 11 18:44:04 2023 ] 	Mean training loss: 0.2907.  Mean training acc: 90.84%.
[ Tue Jul 11 18:44:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 18:44:05 2023 ] Eval epoch: 36
[ Tue Jul 11 18:48:08 2023 ] 	Mean test loss of 258 batches: 0.35660671770514907.
[ Tue Jul 11 18:48:08 2023 ] 	Top1: 89.09%
[ Tue Jul 11 18:48:08 2023 ] 	Top5: 98.33%
[ Tue Jul 11 18:48:08 2023 ] Training epoch: 37
[ Tue Jul 11 19:07:03 2023 ] 	Mean training loss: 0.2312.  Mean training acc: 92.67%.
[ Tue Jul 11 19:07:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 19:07:03 2023 ] Eval epoch: 37
[ Tue Jul 11 19:11:08 2023 ] 	Mean test loss of 258 batches: 0.3447513611943916.
[ Tue Jul 11 19:11:08 2023 ] 	Top1: 89.66%
[ Tue Jul 11 19:11:08 2023 ] 	Top5: 98.36%
[ Tue Jul 11 19:11:08 2023 ] Training epoch: 38
[ Tue Jul 11 19:29:58 2023 ] 	Mean training loss: 0.2097.  Mean training acc: 93.52%.
[ Tue Jul 11 19:29:58 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 19:29:59 2023 ] Eval epoch: 38
[ Tue Jul 11 19:34:02 2023 ] 	Mean test loss of 258 batches: 0.34184198436695473.
[ Tue Jul 11 19:34:03 2023 ] 	Top1: 89.69%
[ Tue Jul 11 19:34:03 2023 ] 	Top5: 98.47%
[ Tue Jul 11 19:34:03 2023 ] Training epoch: 39
[ Tue Jul 11 19:52:46 2023 ] 	Mean training loss: 0.1929.  Mean training acc: 93.98%.
[ Tue Jul 11 19:52:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 19:52:47 2023 ] Eval epoch: 39
[ Tue Jul 11 19:56:50 2023 ] 	Mean test loss of 258 batches: 0.33937669715793556.
[ Tue Jul 11 19:56:50 2023 ] 	Top1: 89.76%
[ Tue Jul 11 19:56:50 2023 ] 	Top5: 98.43%
[ Tue Jul 11 19:56:50 2023 ] Training epoch: 40
[ Tue Jul 11 20:15:41 2023 ] 	Mean training loss: 0.1823.  Mean training acc: 94.29%.
[ Tue Jul 11 20:15:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 20:15:41 2023 ] Eval epoch: 40
[ Tue Jul 11 20:19:44 2023 ] 	Mean test loss of 258 batches: 0.34183711103748443.
[ Tue Jul 11 20:19:44 2023 ] 	Top1: 89.76%
[ Tue Jul 11 20:19:44 2023 ] 	Top5: 98.38%
[ Tue Jul 11 20:19:44 2023 ] Training epoch: 41
[ Tue Jul 11 20:38:42 2023 ] 	Mean training loss: 0.1696.  Mean training acc: 94.85%.
[ Tue Jul 11 20:38:42 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 20:38:42 2023 ] Eval epoch: 41
[ Tue Jul 11 20:42:45 2023 ] 	Mean test loss of 258 batches: 0.34740788126436545.
[ Tue Jul 11 20:42:45 2023 ] 	Top1: 89.79%
[ Tue Jul 11 20:42:45 2023 ] 	Top5: 98.36%
[ Tue Jul 11 20:42:45 2023 ] Training epoch: 42
[ Tue Jul 11 21:01:30 2023 ] 	Mean training loss: 0.1628.  Mean training acc: 94.96%.
[ Tue Jul 11 21:01:30 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 21:01:30 2023 ] Eval epoch: 42
[ Tue Jul 11 21:05:36 2023 ] 	Mean test loss of 258 batches: 0.3415189529660829.
[ Tue Jul 11 21:05:36 2023 ] 	Top1: 89.73%
[ Tue Jul 11 21:05:36 2023 ] 	Top5: 98.42%
[ Tue Jul 11 21:05:36 2023 ] Training epoch: 43
[ Tue Jul 11 21:24:27 2023 ] 	Mean training loss: 0.1517.  Mean training acc: 95.39%.
[ Tue Jul 11 21:24:27 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 21:24:27 2023 ] Eval epoch: 43
[ Tue Jul 11 21:28:29 2023 ] 	Mean test loss of 258 batches: 0.3666149917845578.
[ Tue Jul 11 21:28:29 2023 ] 	Top1: 89.42%
[ Tue Jul 11 21:28:29 2023 ] 	Top5: 98.28%
[ Tue Jul 11 21:28:30 2023 ] Training epoch: 44
[ Tue Jul 11 21:47:22 2023 ] 	Mean training loss: 0.1463.  Mean training acc: 95.71%.
[ Tue Jul 11 21:47:22 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 21:47:23 2023 ] Eval epoch: 44
[ Tue Jul 11 21:51:27 2023 ] 	Mean test loss of 258 batches: 0.3639333930819534.
[ Tue Jul 11 21:51:27 2023 ] 	Top1: 89.55%
[ Tue Jul 11 21:51:27 2023 ] 	Top5: 98.20%
[ Tue Jul 11 21:51:27 2023 ] Training epoch: 45
[ Tue Jul 11 22:10:26 2023 ] 	Mean training loss: 0.1383.  Mean training acc: 95.97%.
[ Tue Jul 11 22:10:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 22:10:27 2023 ] Eval epoch: 45
[ Tue Jul 11 22:14:30 2023 ] 	Mean test loss of 258 batches: 0.3574927441718042.
[ Tue Jul 11 22:14:30 2023 ] 	Top1: 89.39%
[ Tue Jul 11 22:14:30 2023 ] 	Top5: 98.40%
[ Tue Jul 11 22:14:30 2023 ] Training epoch: 46
[ Tue Jul 11 22:33:57 2023 ] 	Mean training loss: 0.1339.  Mean training acc: 96.05%.
[ Tue Jul 11 22:33:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 22:33:57 2023 ] Eval epoch: 46
[ Tue Jul 11 22:38:03 2023 ] 	Mean test loss of 258 batches: 0.35616343419334684.
[ Tue Jul 11 22:38:04 2023 ] 	Top1: 89.22%
[ Tue Jul 11 22:38:04 2023 ] 	Top5: 98.36%
[ Tue Jul 11 22:38:04 2023 ] Training epoch: 47
[ Tue Jul 11 22:57:23 2023 ] 	Mean training loss: 0.1283.  Mean training acc: 96.22%.
[ Tue Jul 11 22:57:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 22:57:23 2023 ] Eval epoch: 47
[ Tue Jul 11 23:01:34 2023 ] 	Mean test loss of 258 batches: 0.36024012711880976.
[ Tue Jul 11 23:01:34 2023 ] 	Top1: 89.60%
[ Tue Jul 11 23:01:34 2023 ] 	Top5: 98.30%
[ Tue Jul 11 23:01:34 2023 ] Training epoch: 48
[ Tue Jul 11 23:20:57 2023 ] 	Mean training loss: 0.1241.  Mean training acc: 96.37%.
[ Tue Jul 11 23:20:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 23:20:58 2023 ] Eval epoch: 48
[ Tue Jul 11 23:25:02 2023 ] 	Mean test loss of 258 batches: 0.37949514147904956.
[ Tue Jul 11 23:25:02 2023 ] 	Top1: 89.02%
[ Tue Jul 11 23:25:02 2023 ] 	Top5: 98.14%
[ Tue Jul 11 23:25:02 2023 ] Training epoch: 49
[ Tue Jul 11 23:44:35 2023 ] 	Mean training loss: 0.1208.  Mean training acc: 96.45%.
[ Tue Jul 11 23:44:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Jul 11 23:44:35 2023 ] Eval epoch: 49
[ Tue Jul 11 23:48:48 2023 ] 	Mean test loss of 258 batches: 0.36449103471786937.
[ Tue Jul 11 23:48:48 2023 ] 	Top1: 89.65%
[ Tue Jul 11 23:48:48 2023 ] 	Top5: 98.19%
[ Tue Jul 11 23:48:48 2023 ] Training epoch: 50
[ Wed Jul 12 00:09:04 2023 ] 	Mean training loss: 0.1220.  Mean training acc: 96.47%.
[ Wed Jul 12 00:09:04 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 00:09:04 2023 ] Eval epoch: 50
[ Wed Jul 12 00:13:19 2023 ] 	Mean test loss of 258 batches: 0.3711866342368745.
[ Wed Jul 12 00:13:19 2023 ] 	Top1: 89.68%
[ Wed Jul 12 00:13:19 2023 ] 	Top5: 98.24%
[ Wed Jul 12 00:13:20 2023 ] Training epoch: 51
[ Wed Jul 12 00:33:21 2023 ] 	Mean training loss: 0.1182.  Mean training acc: 96.45%.
[ Wed Jul 12 00:33:21 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 00:33:21 2023 ] Eval epoch: 51
[ Wed Jul 12 00:37:36 2023 ] 	Mean test loss of 258 batches: 0.3798811933704356.
[ Wed Jul 12 00:37:36 2023 ] 	Top1: 89.29%
[ Wed Jul 12 00:37:36 2023 ] 	Top5: 98.20%
[ Wed Jul 12 00:37:36 2023 ] Training epoch: 52
[ Wed Jul 12 00:57:45 2023 ] 	Mean training loss: 0.1156.  Mean training acc: 96.70%.
[ Wed Jul 12 00:57:45 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 00:57:45 2023 ] Eval epoch: 52
[ Wed Jul 12 01:02:00 2023 ] 	Mean test loss of 258 batches: 0.403193803056497.
[ Wed Jul 12 01:02:00 2023 ] 	Top1: 88.58%
[ Wed Jul 12 01:02:00 2023 ] 	Top5: 98.06%
[ Wed Jul 12 01:02:00 2023 ] Training epoch: 53
[ Wed Jul 12 01:21:55 2023 ] 	Mean training loss: 0.1135.  Mean training acc: 96.76%.
[ Wed Jul 12 01:21:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 01:21:55 2023 ] Eval epoch: 53
[ Wed Jul 12 01:26:11 2023 ] 	Mean test loss of 258 batches: 0.38049541588497254.
[ Wed Jul 12 01:26:11 2023 ] 	Top1: 89.17%
[ Wed Jul 12 01:26:11 2023 ] 	Top5: 98.22%
[ Wed Jul 12 01:26:11 2023 ] Training epoch: 54
[ Wed Jul 12 01:46:00 2023 ] 	Mean training loss: 0.1118.  Mean training acc: 96.70%.
[ Wed Jul 12 01:46:00 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 01:46:00 2023 ] Eval epoch: 54
[ Wed Jul 12 01:50:16 2023 ] 	Mean test loss of 258 batches: 0.4105038236133581.
[ Wed Jul 12 01:50:16 2023 ] 	Top1: 88.41%
[ Wed Jul 12 01:50:16 2023 ] 	Top5: 97.93%
[ Wed Jul 12 01:50:16 2023 ] Training epoch: 55
[ Wed Jul 12 02:10:12 2023 ] 	Mean training loss: 0.1094.  Mean training acc: 96.83%.
[ Wed Jul 12 02:10:12 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 02:10:12 2023 ] Eval epoch: 55
[ Wed Jul 12 02:14:25 2023 ] 	Mean test loss of 258 batches: 0.4109187140959755.
[ Wed Jul 12 02:14:25 2023 ] 	Top1: 88.42%
[ Wed Jul 12 02:14:25 2023 ] 	Top5: 97.99%
[ Wed Jul 12 02:14:25 2023 ] Training epoch: 56
[ Wed Jul 12 02:34:14 2023 ] 	Mean training loss: 0.0779.  Mean training acc: 97.99%.
[ Wed Jul 12 02:34:15 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 02:34:15 2023 ] Eval epoch: 56
[ Wed Jul 12 02:38:25 2023 ] 	Mean test loss of 258 batches: 0.35858050266699504.
[ Wed Jul 12 02:38:25 2023 ] 	Top1: 90.09%
[ Wed Jul 12 02:38:25 2023 ] 	Top5: 98.16%
[ Wed Jul 12 02:38:25 2023 ] Training epoch: 57
[ Wed Jul 12 02:57:28 2023 ] 	Mean training loss: 0.0608.  Mean training acc: 98.51%.
[ Wed Jul 12 02:57:28 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 02:57:28 2023 ] Eval epoch: 57
[ Wed Jul 12 03:01:33 2023 ] 	Mean test loss of 258 batches: 0.36390465350691664.
[ Wed Jul 12 03:01:33 2023 ] 	Top1: 90.11%
[ Wed Jul 12 03:01:33 2023 ] 	Top5: 98.16%
[ Wed Jul 12 03:01:34 2023 ] Training epoch: 58
[ Wed Jul 12 03:20:23 2023 ] 	Mean training loss: 0.0580.  Mean training acc: 98.60%.
[ Wed Jul 12 03:20:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 03:20:23 2023 ] Eval epoch: 58
[ Wed Jul 12 03:24:28 2023 ] 	Mean test loss of 258 batches: 0.3690682598209196.
[ Wed Jul 12 03:24:28 2023 ] 	Top1: 89.75%
[ Wed Jul 12 03:24:29 2023 ] 	Top5: 98.20%
[ Wed Jul 12 03:24:29 2023 ] Training epoch: 59
[ Wed Jul 12 03:43:25 2023 ] 	Mean training loss: 0.0529.  Mean training acc: 98.77%.
[ Wed Jul 12 03:43:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 03:43:25 2023 ] Eval epoch: 59
[ Wed Jul 12 03:47:28 2023 ] 	Mean test loss of 258 batches: 0.37228308801445387.
[ Wed Jul 12 03:47:28 2023 ] 	Top1: 89.89%
[ Wed Jul 12 03:47:28 2023 ] 	Top5: 98.12%
[ Wed Jul 12 03:47:28 2023 ] Training epoch: 60
[ Wed Jul 12 04:06:34 2023 ] 	Mean training loss: 0.0522.  Mean training acc: 98.78%.
[ Wed Jul 12 04:06:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 04:06:35 2023 ] Eval epoch: 60
[ Wed Jul 12 04:10:37 2023 ] 	Mean test loss of 258 batches: 0.36790773970645296.
[ Wed Jul 12 04:10:37 2023 ] 	Top1: 89.98%
[ Wed Jul 12 04:10:37 2023 ] 	Top5: 98.14%
[ Wed Jul 12 04:10:37 2023 ] Training epoch: 61
[ Wed Jul 12 04:29:35 2023 ] 	Mean training loss: 0.0491.  Mean training acc: 98.89%.
[ Wed Jul 12 04:29:35 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 04:29:35 2023 ] Eval epoch: 61
[ Wed Jul 12 04:33:38 2023 ] 	Mean test loss of 258 batches: 0.36707699682217004.
[ Wed Jul 12 04:33:38 2023 ] 	Top1: 90.05%
[ Wed Jul 12 04:33:38 2023 ] 	Top5: 98.18%
[ Wed Jul 12 04:33:38 2023 ] Training epoch: 62
[ Wed Jul 12 04:52:47 2023 ] 	Mean training loss: 0.0451.  Mean training acc: 99.07%.
[ Wed Jul 12 04:52:47 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 04:52:48 2023 ] Eval epoch: 62
[ Wed Jul 12 04:56:48 2023 ] 	Mean test loss of 258 batches: 0.3636476932338966.
[ Wed Jul 12 04:56:48 2023 ] 	Top1: 90.23%
[ Wed Jul 12 04:56:49 2023 ] 	Top5: 98.16%
[ Wed Jul 12 04:56:49 2023 ] Training epoch: 63
[ Wed Jul 12 05:15:39 2023 ] 	Mean training loss: 0.0453.  Mean training acc: 99.01%.
[ Wed Jul 12 05:15:39 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 05:15:40 2023 ] Eval epoch: 63
[ Wed Jul 12 05:19:41 2023 ] 	Mean test loss of 258 batches: 0.36910929161217787.
[ Wed Jul 12 05:19:41 2023 ] 	Top1: 90.03%
[ Wed Jul 12 05:19:42 2023 ] 	Top5: 98.13%
[ Wed Jul 12 05:19:42 2023 ] Training epoch: 64
[ Wed Jul 12 05:38:33 2023 ] 	Mean training loss: 0.0461.  Mean training acc: 98.96%.
[ Wed Jul 12 05:38:33 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 05:38:33 2023 ] Eval epoch: 64
[ Wed Jul 12 05:42:34 2023 ] 	Mean test loss of 258 batches: 0.3684199768905492.
[ Wed Jul 12 05:42:35 2023 ] 	Top1: 90.04%
[ Wed Jul 12 05:42:35 2023 ] 	Top5: 98.13%
[ Wed Jul 12 05:42:35 2023 ] Training epoch: 65
[ Wed Jul 12 06:01:23 2023 ] 	Mean training loss: 0.0445.  Mean training acc: 98.99%.
[ Wed Jul 12 06:01:23 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 06:01:24 2023 ] Eval epoch: 65
[ Wed Jul 12 06:05:25 2023 ] 	Mean test loss of 258 batches: 0.37138006397226986.
[ Wed Jul 12 06:05:25 2023 ] 	Top1: 89.98%
[ Wed Jul 12 06:05:25 2023 ] 	Top5: 98.14%
[ Wed Jul 12 06:05:25 2023 ] Training epoch: 66
[ Wed Jul 12 06:24:16 2023 ] 	Mean training loss: 0.0427.  Mean training acc: 99.03%.
[ Wed Jul 12 06:24:16 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 06:24:16 2023 ] Eval epoch: 66
[ Wed Jul 12 06:28:21 2023 ] 	Mean test loss of 258 batches: 0.3700115308237746.
[ Wed Jul 12 06:28:21 2023 ] 	Top1: 89.90%
[ Wed Jul 12 06:28:21 2023 ] 	Top5: 98.16%
[ Wed Jul 12 06:28:22 2023 ] Training epoch: 67
[ Wed Jul 12 06:47:46 2023 ] 	Mean training loss: 0.0410.  Mean training acc: 99.16%.
[ Wed Jul 12 06:47:46 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 06:47:46 2023 ] Eval epoch: 67
[ Wed Jul 12 06:51:55 2023 ] 	Mean test loss of 258 batches: 0.37351303843622524.
[ Wed Jul 12 06:51:56 2023 ] 	Top1: 89.95%
[ Wed Jul 12 06:51:56 2023 ] 	Top5: 98.11%
[ Wed Jul 12 06:51:56 2023 ] Training epoch: 68
[ Wed Jul 12 07:11:06 2023 ] 	Mean training loss: 0.0411.  Mean training acc: 99.16%.
[ Wed Jul 12 07:11:06 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 07:11:06 2023 ] Eval epoch: 68
[ Wed Jul 12 07:15:16 2023 ] 	Mean test loss of 258 batches: 0.3693485625932903.
[ Wed Jul 12 07:15:16 2023 ] 	Top1: 90.13%
[ Wed Jul 12 07:15:16 2023 ] 	Top5: 98.17%
[ Wed Jul 12 07:15:16 2023 ] Training epoch: 69
[ Wed Jul 12 07:34:25 2023 ] 	Mean training loss: 0.0411.  Mean training acc: 99.12%.
[ Wed Jul 12 07:34:25 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 07:34:25 2023 ] Eval epoch: 69
[ Wed Jul 12 07:38:36 2023 ] 	Mean test loss of 258 batches: 0.3703713001856624.
[ Wed Jul 12 07:38:37 2023 ] 	Top1: 90.01%
[ Wed Jul 12 07:38:37 2023 ] 	Top5: 98.14%
[ Wed Jul 12 07:38:37 2023 ] Training epoch: 70
[ Wed Jul 12 07:57:53 2023 ] 	Mean training loss: 0.0399.  Mean training acc: 99.19%.
[ Wed Jul 12 07:57:53 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 07:57:53 2023 ] Eval epoch: 70
[ Wed Jul 12 08:02:05 2023 ] 	Mean test loss of 258 batches: 0.3737132158346994.
[ Wed Jul 12 08:02:05 2023 ] 	Top1: 89.91%
[ Wed Jul 12 08:02:05 2023 ] 	Top5: 98.10%
[ Wed Jul 12 08:02:05 2023 ] Training epoch: 71
[ Wed Jul 12 08:21:09 2023 ] 	Mean training loss: 0.0390.  Mean training acc: 99.14%.
[ Wed Jul 12 08:21:09 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 08:21:09 2023 ] Eval epoch: 71
[ Wed Jul 12 08:25:17 2023 ] 	Mean test loss of 258 batches: 0.37128424793193043.
[ Wed Jul 12 08:25:17 2023 ] 	Top1: 90.19%
[ Wed Jul 12 08:25:17 2023 ] 	Top5: 98.13%
[ Wed Jul 12 08:25:17 2023 ] Training epoch: 72
[ Wed Jul 12 08:44:20 2023 ] 	Mean training loss: 0.0407.  Mean training acc: 99.08%.
[ Wed Jul 12 08:44:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 08:44:20 2023 ] Eval epoch: 72
[ Wed Jul 12 08:48:26 2023 ] 	Mean test loss of 258 batches: 0.37328016106039286.
[ Wed Jul 12 08:48:26 2023 ] 	Top1: 90.09%
[ Wed Jul 12 08:48:26 2023 ] 	Top5: 98.16%
[ Wed Jul 12 08:48:26 2023 ] Training epoch: 73
[ Wed Jul 12 09:07:40 2023 ] 	Mean training loss: 0.0365.  Mean training acc: 99.26%.
[ Wed Jul 12 09:07:40 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 09:07:40 2023 ] Eval epoch: 73
[ Wed Jul 12 09:11:53 2023 ] 	Mean test loss of 258 batches: 0.3777553726911776.
[ Wed Jul 12 09:11:53 2023 ] 	Top1: 90.00%
[ Wed Jul 12 09:11:53 2023 ] 	Top5: 98.07%
[ Wed Jul 12 09:11:53 2023 ] Training epoch: 74
[ Wed Jul 12 09:30:57 2023 ] 	Mean training loss: 0.0357.  Mean training acc: 99.28%.
[ Wed Jul 12 09:30:57 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 09:30:57 2023 ] Eval epoch: 74
[ Wed Jul 12 09:35:05 2023 ] 	Mean test loss of 258 batches: 0.3719686167603431.
[ Wed Jul 12 09:35:05 2023 ] 	Top1: 90.08%
[ Wed Jul 12 09:35:05 2023 ] 	Top5: 98.09%
[ Wed Jul 12 09:35:05 2023 ] Training epoch: 75
[ Wed Jul 12 09:54:20 2023 ] 	Mean training loss: 0.0353.  Mean training acc: 99.29%.
[ Wed Jul 12 09:54:20 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 09:54:20 2023 ] Eval epoch: 75
[ Wed Jul 12 09:58:35 2023 ] 	Mean test loss of 258 batches: 0.3716970855449579.
[ Wed Jul 12 09:58:35 2023 ] 	Top1: 90.06%
[ Wed Jul 12 09:58:35 2023 ] 	Top5: 98.07%
[ Wed Jul 12 09:58:35 2023 ] Training epoch: 76
[ Wed Jul 12 10:17:36 2023 ] 	Mean training loss: 0.0366.  Mean training acc: 99.23%.
[ Wed Jul 12 10:17:36 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 10:17:37 2023 ] Eval epoch: 76
[ Wed Jul 12 10:21:45 2023 ] 	Mean test loss of 258 batches: 0.3732916148697106.
[ Wed Jul 12 10:21:45 2023 ] 	Top1: 90.11%
[ Wed Jul 12 10:21:45 2023 ] 	Top5: 98.07%
[ Wed Jul 12 10:21:45 2023 ] Training epoch: 77
[ Wed Jul 12 10:40:50 2023 ] 	Mean training loss: 0.0344.  Mean training acc: 99.31%.
[ Wed Jul 12 10:40:50 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 10:40:50 2023 ] Eval epoch: 77
[ Wed Jul 12 10:44:57 2023 ] 	Mean test loss of 258 batches: 0.37190801315659355.
[ Wed Jul 12 10:44:58 2023 ] 	Top1: 90.09%
[ Wed Jul 12 10:44:58 2023 ] 	Top5: 98.12%
[ Wed Jul 12 10:44:58 2023 ] Training epoch: 78
[ Wed Jul 12 11:04:03 2023 ] 	Mean training loss: 0.0332.  Mean training acc: 99.34%.
[ Wed Jul 12 11:04:03 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 11:04:03 2023 ] Eval epoch: 78
[ Wed Jul 12 11:08:11 2023 ] 	Mean test loss of 258 batches: 0.36928928029080926.
[ Wed Jul 12 11:08:12 2023 ] 	Top1: 90.17%
[ Wed Jul 12 11:08:12 2023 ] 	Top5: 98.14%
[ Wed Jul 12 11:08:12 2023 ] Training epoch: 79
[ Wed Jul 12 11:27:13 2023 ] 	Mean training loss: 0.0337.  Mean training acc: 99.34%.
[ Wed Jul 12 11:27:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 11:27:13 2023 ] Eval epoch: 79
[ Wed Jul 12 11:31:26 2023 ] 	Mean test loss of 258 batches: 0.3694564139492117.
[ Wed Jul 12 11:31:26 2023 ] 	Top1: 90.23%
[ Wed Jul 12 11:31:27 2023 ] 	Top5: 98.16%
[ Wed Jul 12 11:31:27 2023 ] Training epoch: 80
[ Wed Jul 12 11:50:26 2023 ] 	Mean training loss: 0.0329.  Mean training acc: 99.38%.
[ Wed Jul 12 11:50:26 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 11:50:26 2023 ] Eval epoch: 80
[ Wed Jul 12 11:54:36 2023 ] 	Mean test loss of 258 batches: 0.3711971511789995.
[ Wed Jul 12 11:54:36 2023 ] 	Top1: 90.15%
[ Wed Jul 12 11:54:36 2023 ] 	Top5: 98.11%
[ Wed Jul 12 11:54:36 2023 ] Training epoch: 81
[ Wed Jul 12 12:13:34 2023 ] 	Mean training loss: 0.0328.  Mean training acc: 99.43%.
[ Wed Jul 12 12:13:34 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 12:13:35 2023 ] Eval epoch: 81
[ Wed Jul 12 12:17:48 2023 ] 	Mean test loss of 258 batches: 0.37021351766649835.
[ Wed Jul 12 12:17:48 2023 ] 	Top1: 90.03%
[ Wed Jul 12 12:17:48 2023 ] 	Top5: 98.11%
[ Wed Jul 12 12:17:48 2023 ] Training epoch: 82
[ Wed Jul 12 12:36:55 2023 ] 	Mean training loss: 0.0325.  Mean training acc: 99.35%.
[ Wed Jul 12 12:36:55 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 12:36:56 2023 ] Eval epoch: 82
[ Wed Jul 12 12:41:06 2023 ] 	Mean test loss of 258 batches: 0.37056512448416895.
[ Wed Jul 12 12:41:06 2023 ] 	Top1: 90.23%
[ Wed Jul 12 12:41:06 2023 ] 	Top5: 98.12%
[ Wed Jul 12 12:41:06 2023 ] Training epoch: 83
[ Wed Jul 12 13:00:13 2023 ] 	Mean training loss: 0.0335.  Mean training acc: 99.33%.
[ Wed Jul 12 13:00:13 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 13:00:13 2023 ] Eval epoch: 83
[ Wed Jul 12 13:04:19 2023 ] 	Mean test loss of 258 batches: 0.3697116469581749.
[ Wed Jul 12 13:04:19 2023 ] 	Top1: 90.18%
[ Wed Jul 12 13:04:19 2023 ] 	Top5: 98.08%
[ Wed Jul 12 13:04:19 2023 ] Training epoch: 84
[ Wed Jul 12 13:23:18 2023 ] 	Mean training loss: 0.0306.  Mean training acc: 99.45%.
[ Wed Jul 12 13:23:19 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 13:23:19 2023 ] Eval epoch: 84
[ Wed Jul 12 13:27:26 2023 ] 	Mean test loss of 258 batches: 0.3751415931800193.
[ Wed Jul 12 13:27:26 2023 ] 	Top1: 90.14%
[ Wed Jul 12 13:27:26 2023 ] 	Top5: 98.14%
[ Wed Jul 12 13:27:27 2023 ] Training epoch: 85
[ Wed Jul 12 13:46:41 2023 ] 	Mean training loss: 0.0346.  Mean training acc: 99.34%.
[ Wed Jul 12 13:46:41 2023 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Jul 12 13:46:41 2023 ] Eval epoch: 85
[ Wed Jul 12 13:50:56 2023 ] 	Mean test loss of 258 batches: 0.37286716252709773.
[ Wed Jul 12 13:50:56 2023 ] 	Top1: 90.16%
[ Wed Jul 12 13:50:56 2023 ] 	Top5: 98.11%
[ Wed Jul 12 13:55:05 2023 ] Best accuracy: 0.9023473039364348
[ Wed Jul 12 13:55:05 2023 ] Epoch number: 62
[ Wed Jul 12 13:55:05 2023 ] Model name: train/ntu60/xsub/nctt1_ctrgcn_joint
[ Wed Jul 12 13:55:05 2023 ] Model total number of params: 1731776
[ Wed Jul 12 13:55:05 2023 ] Weight decay: 0.0004
[ Wed Jul 12 13:55:05 2023 ] Base LR: 0.1
[ Wed Jul 12 13:55:05 2023 ] Batch Size: 64
[ Wed Jul 12 13:55:05 2023 ] Test Batch Size: 64
[ Wed Jul 12 13:55:05 2023 ] seed: 1
